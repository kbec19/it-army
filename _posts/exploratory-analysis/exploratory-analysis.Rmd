---
title: "Exploratory Analysis"
description: |
  DACSS 603 Final Project Work: "Analyzing Data"
categories:
  - statistics
  - final project
  - IT Army of Ukraine
author:
  - name: Kristina Becvar
date: 2022-04-24
output:
  distill::distill_article:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(dplyr)
library(ggplot2)
library(broom)
library(here)
```

# Data Sources

## DDOS User Observations

The primary data is a set of observations of users of a novice "hacking tool" to engage in DDOS (denial of service) attacks against Russian targets in March 2022. The data contains a total of users cumulatively for each day of the series March 2 through March 11, and the users represent participants from 98 counties.

## WVS/EVS

I will also be using a data set of observations from the World Values Survey conducted from 2017-2021 as a joint project between the World Values Survey and the European Values Studies. This data was released in July 2021, and contains responses from ~135,000 respondents among 95 countries.

## Spike/Newswhip

The third is a data set of media coverage (media articles and social media mentions) of the Ukrainian minister's call for volunteers for the "IT Army of Ukraine" to help fight the invasion of Russia on the digital front. 

# Background

## Gathering DDOS User Data

## Gathering WVS/EVS Data

## Gathering Spike/Newswhip Data



# Hypothesis

I am looking at a model where the outcome is the number of DDOS attacks originated from a given country and explanatory variables are WVS activism scores, media coverage, and other controls.


# Data Analysis

## DDOS Users

The data I imported for this first exploration is a data frame consisting of 98 observations with the columns:

* Country Name
* Population (as indicated by the U.S. CIA World factbook website)
* Region (as indicated by the UN classifications)
* Cumulative total number of users of the DDOS attack tool from each representative country as of March 11, 2022

```{r code_folding = TRUE}
#load the data
ddos <- read_csv("cumulative_observations.csv")
#summarize the data
options(scipen = 999)
summary(ddos)
```

```{r code_folding = TRUE}
#load the data
ddos <- read_csv("active_observations.csv")
#assign column names to represent variables accurately
colnames(ddos) <- c("Country", "Population", "Region", "March2", "March3", "March4", "March5", "March6", "March7", "March8", "March9", "March10", "March11")
#summarize the data
options(scipen = 999)
head(ddos)
```

The total DDOS users as of the first day of observations, March 2, 2022, and the last day available for observation, March 11, 2022 began at 7,850 and grew to a total of 48,879.

```{r code_folding = TRUE}
sum(ddos$March2)
sum(ddos$March11)
```

However, I am not going to examine the panel data; I am only going to look at the cumulative data - or the count of users on the last day of observations, March 11.

It is still important to be able to visualize the dramatic change in user count over time, even if I am not analyzing the time series in this analysis.

```{r code_folding = TRUE}
regional_observations <- read_csv("regional_observations.csv", 
    col_types = cols(Date = col_date(format = "%m/%d/%Y")))
ddos_regions <- as_tibble(regional_observations) 

ggplot(ddos_regions, aes(x = Date)) +
  geom_line(aes(y = Africa, colour = "Africa")) +
  geom_line(aes(y = Central_America, colour = "Central America")) +
    geom_line(aes(y = Central_America, colour = "Central America")) +
    geom_line(aes(y = Central_Asia, colour = "Central Asia")) +
    geom_line(aes(y = Eastern_Europe, colour = "Eastern Europe")) +
    geom_line(aes(y = North_America, colour = "North America")) +
    geom_line(aes(y = Northern_Europe, colour = "Northern Europe")) +
    geom_line(aes(y = Oceania, colour = "Oceania")) +
    geom_line(aes(y = Southeastern_Asia, colour = "Southeastern Asia")) +
    geom_line(aes(y = South_America, colour = "South America")) +
    geom_line(aes(y = Southern_Europe, colour = "Southern Europe")) +
    geom_line(aes(y = Western_Asia, colour = "Western Asia")) +
    geom_line(aes(y = Western_Europe, colour = "Western Europe")) +
  scale_colour_discrete((name = "Region")) +
  xlab("Dates") +
  ylab("Users") +
  ggtitle("Increase in Users by Date") +
  theme_minimal()

```

I also want to plot the relationships between key variables of this dataset:

```{r code_folding=TRUE}
#create plot
ggplot(ddos, aes(x = log(Population), y = log(March11), color = Region)) +
  geom_point () +
  facet_wrap("Region")
```

What I want to look at is the linear model of the relationship between the population of each country with participating users and the corresponding sample of users from that country.

I want to first simplify my data set

```{r code_folding=TRUE}
ddos_final <- read_csv("cumulative_observations.csv")
ddos_df <- ddos_final %>% 
  select(c(Population, Users))
```


```{r code_folding=TRUE}
library(cowplot)
gg1 <- ggplot(ddos_df, aes(x=Population, y=Users)) +
   geom_point() +
   geom_smooth(method=lm,se=TRUE,fullrange=TRUE,color="goldenrod") +
   labs(title= "Population and Users",
        x= "Population",
        y = "Users") +
    theme_minimal_hgrid()
gg1

```

```{r}
gg1b <- ggplot(ddos_df, aes(x=log(Population), y=log(Users))) +
  geom_point() +
  geom_smooth(method=lm,se=TRUE,fullrange=TRUE,color="goldenrod") +
   labs(title= "Log: Population and Users",
        x= "Population (log)",
        y = "Users (log)") +
   theme_minimal_hgrid()

gg1b
```


It is clear that there is no correlation between a country's population and the number of users of the DDOS tool.

# IVS Data

The next data source I want to incorporate is the IVS data set. This brings in an overwhelming 135,000 observations of 231 variables. I selected the columns I am interested in working with and saved as a .csv file, which I will read in for the rest of the analysis.

To make matching easier, I used the "countrycode" package to assign proper country names to the ISO-3 numeric code from the data set.

```{r code_folding = TRUE}
#read in .dta file
#library(haven)
#ivs_data <- read_dta("data/ivs/ZA7505_v2-0-0.dta")
#head(ivs_data[33:42])
#write.csv(ivs_data, file = "./data/ivs/ivs_data.csv", row.names = TRUE)
#select relevant data
#ivs_subset <- select(ivs_data,10,34,35,40:50,106,109:114,119:138,150:162,166,188:196,199,201,210:214,222,224,225,230,231)
#ivs_df <- as.data.frame(ivs_subset)
#load package for converting country codes
#library(countrycode)
#ivs_df$country.name <- countrycode(ivs_df$cntry, origin = "iso3n", destination = "country.name")

rm(list = ls())
ivs_clean <- read.csv("ivs_df_names.csv")
ivs_clean <- as_tibble(ivs_clean)
names(ivs_clean)[1] <- 'country'
head(ivs_clean)
```

# Modeling Data

There is some changes needed to make the data more manageable. I want to clean up some of the data by assigning negative values to "0" when applicable. 

```{r code_folding = TRUE}
```


